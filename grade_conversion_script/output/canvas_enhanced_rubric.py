import enum
from itertools import chain
import pandas as pd
from pathlib import Path

from typing import * # pyright: ignore[reportWildcardImportFromLibrary]
import numbers as num
import pandera.pandas as pa
from numpy.ma.extras import row_stack
from pandera.typing import DataFrame

from .base import OutputFormat

from grade_conversion_script.util import AliasRecord
from grade_conversion_script.util.custom_types import Matcher, RubricMatcher, SisId, StudentPtsById
from grade_conversion_script.util.funcs import associate_unrecognized_entities, best_effort_is_name, contains_row_for, iter_by_element, is_pd_value_present, reindex_to
from grade_conversion_script.util.tui import interactive_rubric_criteria_match, interactive_alias_match

class CanvasEnhancedRubricOutputFormat(OutputFormat):
    '''
    Populate an Enhanced Rubric file generated by Canvas.

    Does not consider Rating label when determining
    whether an action would overwrite an existing grade.

    >>> student_ar = AliasRecord()
    >>> rubric_csv = pd.DataFrame({
    ...                         'Student Name':           ["Name One",],
    ...                         'Criterion 1 - Rating':   ["Any Text",],
    ...                         'Criterion 1 - Points':   ["",        ],
    ...                         'Criterion 1 - Comments': ["",        ],
    ...                         'Criterion 2 - Rating':   ["",        ],
    ...                         'Criterion 2 - Points':   ["",        ],
    ...                         'Criterion 2 - Comments': ["excused", ],
    ...                     })
    >>> def raise_if_match(*args, **kwargs) -> str:
    ...     from itertools import chain
    ...     if any(obj for obj in chain(args, kwargs.values())):
    ...         raise Exception("Matching not expected")
    ...     return dict()
    >>> cerubric_output = CanvasEnhancedRubricOutputFormat(
    ...     rubric_csv,
    ...     student_ar,
    ...     unrecognized_name_match=raise_if_match,
    ...     rubric_criteria_match=(
    ...         lambda given_labels, dest_labels:
    ...             dict(zip(given_labels, dest_labels))
    ...     ),
    ...     replace_existing=False,
    ...     warn_existing=True
    ... )

    >>> student_ar.add_together(['name1', 'Name One'])
    >>> student_ar.id_of('name1')
    400
    >>> grades = pd.DataFrame({
    ...     'id'   : [400,],
    ...     'crit1': [3,  ],
    ...     'crit2': [4,  ],
    ... }).set_index('id', drop=True)
    >>> grades
         crit1  crit2
     id
    400      3      4

    >>> new_csv = cerubric_output.format(grades)
    Keeping existing grade values:
        	(student: Name One,	criterion: Criterion 2)	(Comment: excused)
    >>> new_csv[['Student Name', 'Criterion 1 - Points', 'Criterion 2 - Points']]
      Student Name  Criterion 1 - Points  Criterion 2 - Points
    0     Name One                     3                   NaN
    '''

    class CriterionField(enum.Enum):
        PTS_LABEL = " - Rating"
        PTS = " - Points"
        COMMENTS = " - Comments"

        def col_name_for(self, criterion: str) -> str:
            return criterion + self.value

        @classmethod
        def remove_field_suffix(cls, col_name: str) -> str:
            field = cls.get_field_type(col_name)
            if not field:
                raise ValueError(f"{col_name} does not end in known field suffix")
            return col_name.removesuffix(field.value)

        @classmethod
        def get_field_type(cls, col_name: str) -> Self | None:
            for field in cls:
                if col_name.endswith(field.value):
                    return field
            return None

    def __init__(
            self,
            rubric_csv: pd.DataFrame,
            student_aliases: AliasRecord,
            unrecognized_name_match: Matcher[str, str] = interactive_alias_match,
            rubric_criteria_match: RubricMatcher = interactive_rubric_criteria_match,
            *,
            replace_existing: bool,
            warn_existing: bool
        ):
        super().__init__(student_aliases)

        self.rubric_template = rubric_csv
        
        self.replace_existing = replace_existing
        self.warn_existing = warn_existing

        self.unrecognized_name_match = unrecognized_name_match
        self.rubric_criteria_match = rubric_criteria_match

    def merge_conflict_values(self, existing: pd.DataFrame, incoming: pd.DataFrame, index_to_alias_id: pd.Series, full_existing: pd.DataFrame) -> tuple[pd.DataFrame, str | None]:
        '''
        Columns of `existing` and `incoming` have ' - Points' suffix'.
        '''
        # constants
        subline_start = "\n    "
        tab = "\t"
        def conflicts_detail():
            for row, col, new_val in iter_by_element(incoming):
                if pd.isna(new_val):
                    continue
                assert isinstance(row, (num.Real, str))
                assert isinstance(col, str)

                existing_val = existing.loc[row, col]
                alias_id: int = index_to_alias_id[row]
                student_name = self.student_aliases.best_effort_alias(best_effort_is_name, id=alias_id)
                criterion = self.CriterionField.remove_field_suffix(col)

                rating= full_existing.loc[row, criterion + self.CriterionField.PTS_LABEL.value]
                comment = full_existing.loc[row, criterion + self.CriterionField.COMMENTS.value]

                yield (existing_val, new_val, student_name, criterion, rating, comment)

        pd.testing.assert_index_equal(existing.index, incoming.index)
        assert len(existing.columns) == len(incoming.columns)
        assert all(x.endswith(" - Points") for x in chain(existing.columns, incoming.columns))

        if existing.empty:
            return (existing, None)

        if self.replace_existing:
            values = incoming
            message = subline_start.join((
                f"Replacing existing grade values (keeping values for Rating and Comment):",
                *(
                    tab.join((
                        f"{existing_val}",
                        f"(new: {new_val},",
                        f"student: {student_name},",
                        f"criterion: {criterion})",
                        f"(Rating: {rating},",
                        f"Comment: {comment})",
                    ))
                    for existing_val, new_val, student_name, criterion, rating, comment
                    in conflicts_detail()
                )
            ))
        else:
            values = existing
            message = subline_start.join((
                f"Keeping existing grade values:",
                *(
                    tab.join((
                        f"{existing_val}",
                        f"(student: {student_name},",
                        f"criterion: {criterion})",
                        f"(Comment: {comment})",
                    ))
                    for existing_val, _, student_name, criterion, _, comment
                    in conflicts_detail()
                )
            ))

        return (values, message if self.warn_existing else None)

    @override
    @pa.check_types
    def format(self, grades: DataFrame[StudentPtsById]) -> pd.DataFrame:

        new_rubric = self.rubric_template.copy()

        # Perform name matching
        associate_unrecognized_entities(
            self.student_aliases,
            self.unrecognized_name_match,
            input_ids=grades.index,
            dest_alias_lists=new_rubric['Student Name']
        )
        # matching is applied inside of self.student_aliases

        # Perform matching: input column label -> rubric criterion
        user_criteria = grades.columns.to_list()
        canvas_criteria = (
            self.CriterionField.remove_field_suffix(col_name)
            for col_name in new_rubric.columns
            if col_name.endswith(self.CriterionField.PTS.value) # pull one column label for each criterion
        )
        given_to_dest_criteria = self.rubric_criteria_match(
            given_labels=user_criteria,
            dest_labels=canvas_criteria
        )
        grades.columns = grades.columns.map(given_to_dest_criteria)

        # Reindex grades to align with output
        id_by_rubric_row = self.student_aliases.id_of_df(
            new_rubric,
            'Student Name',
            expect_new_entities=True,
            collect_new_aliases=True
        )
        incoming_grades_aligned_rows = cast(
            pd.DataFrame,
            reindex_to(
                to_realign=grades,
                target_ids=id_by_rubric_row
            )
        )

        # Resolve + Set values (handle replace_existing, warn_existing)

        # determine which elements are conflicting
        determines_existing = (self.CriterionField.PTS, self.CriterionField.COMMENTS)
        # `has_existing` and `has_incoming` have
        # index like `new_rubric` but
        # columns like `incoming_grades_aligned_rows`.
        has_existing = (
            new_rubric.loc[
                : , (
                    new_rubric.columns.to_series().map(
                        lambda col_name:
                            self.CriterionField.get_field_type(col_name)
                            in determines_existing
                    )
                )
            ].groupby( # pyright: ignore[reportUnknownMemberType, reportCallIssue]
                lambda col: self.CriterionField.remove_field_suffix(col),
                as_index=True,
                sort=False,
                axis='columns'
            ).apply(
                lambda group: (group.notna() & ~group.eq('')).any(axis="columns"),
            )
        )
        has_incoming: pd.DataFrame = (
            incoming_grades_aligned_rows
            .notna()
            .reindex(
                fill_value=bool(False),
                index=new_rubric.index
            )
        )
        conflicting = has_existing & has_incoming
        conflicting_aligned_2D = conflicting.rename(columns=self.CriterionField.PTS.col_name_for)
        non_conflicting = (~has_existing) & has_incoming
        non_conflicting_aligned_2D = non_conflicting.rename(columns=self.CriterionField.PTS.col_name_for)

        # rename incoming grades to end with ' - Points' for convenience
        incoming_grades_aligned_2D = incoming_grades_aligned_rows.rename(
            columns = lambda col_name: (
                self.CriterionField.PTS.col_name_for(col_name)
            )
        )

        # set conflicting
        conflict_vals, warning_msg = self.merge_conflict_values(
            existing = new_rubric.where(conflicting_aligned_2D)
                        .dropna(axis=0, how='all').dropna(axis=1, how='all'),
            incoming = incoming_grades_aligned_2D.where(conflicting_aligned_2D)
                        .dropna(axis=0, how='all').dropna(axis=1, how='all'),
            index_to_alias_id = id_by_rubric_row,
            full_existing = new_rubric
        )
        new_rubric.mask(
            conflicting_aligned_2D.reindex_like(new_rubric).fillna(False),
            other=conflict_vals,
            inplace=True
        )
        if warning_msg:
            print(warning_msg)

        # set non-conflicting
        non_conflict_vals = incoming_grades_aligned_2D[non_conflicting_aligned_2D]
        new_rubric = new_rubric.mask(
            non_conflicting_aligned_2D.reindex_like(new_rubric).fillna(False),
            other=non_conflict_vals
        )

        # Return, asserts

        # We only touched "Points" columns that were specified in the input
        modified_columns: list[str] = [f"{criterion} - Points"
                                       for criterion in grades.columns]
        new_rubric[modified_columns] = (
            new_rubric[modified_columns].apply(pd.to_numeric, downcast='integer')
        )

        pd.testing.assert_frame_equal(
            self.rubric_template[[*new_rubric.columns]].fillna('')
                .drop(modified_columns, axis='columns', inplace=False),
            new_rubric.fillna('')
                .drop(modified_columns, axis='columns', inplace=False),
            check_dtype=False,
        )

        return new_rubric
    
    @override
    @classmethod
    def write_file(cls, self_output: pd.DataFrame, filepath: Path) -> None:
        self_output.to_csv(filepath, index=False, header=True)